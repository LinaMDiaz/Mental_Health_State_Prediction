{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc125b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial input columns: 74\n",
      "Redundant columns removed: 1\n",
      "Final selected input columns (~20):\n",
      " - Survey Year\n",
      " - Region Served\n",
      " - Age Group\n",
      " - Sex\n",
      " - Transgender\n",
      " - Sexual Orientation\n",
      " - Hispanic Ethnicity\n",
      " - Race\n",
      " - Preferred Language\n",
      " - Religious Preference\n",
      " - Three Digit Residence Zip Code\n",
      " - Living Situation\n",
      " - Household Composition\n",
      " - Veteran Status\n",
      " - Employment Status\n",
      " - Number Of Hours Worked Each Week\n",
      " - Education Status\n",
      " - Special Education Services\n",
      " - Criminal Justice Status\n",
      " - Mental Illness\n",
      "\n",
      "Reduced dataset saved to 'reduced_patient_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# === 1. Load the dataset ===\n",
    "df = pd.read_csv(\"C:/Dell/All Documents/Vợ iu/University/DSTI/Course 1 - Machine Learning with Python Labs/Project 2/Patient_Characteristics_Survey__PCS___2019_Cleaned.csv\")\n",
    "\n",
    "# === 2. Define column groupings ===\n",
    "output_columns = [\"Principal Diagnosis Class\", \"Additional Diagnosis Class\"]\n",
    "\n",
    "demographic_cols = [\n",
    "    \"Survey Year\", \"Region Served\", \"Age Group\", \"Sex\", \"Transgender\", \"Sexual Orientation\",\n",
    "    \"Hispanic Ethnicity\", \"Race\", \"Preferred Language\", \"Religious Preference\", \n",
    "    \"Three Digit Residence Zip Code\"\n",
    "]\n",
    "\n",
    "social_cols = [\n",
    "    \"Living Situation\", \"Household Composition\", \"Veteran Status\",\n",
    "    \"Employment Status\", \"Number Of Hours Worked Each Week\", \"Education Status\", \n",
    "    \"Special Education Services\", \"Criminal Justice Status\"\n",
    "]\n",
    "\n",
    "clinic_cols = [\n",
    "    \"Mental Illness\", \"Intellectual Disability\", \"Autism Spectrum\", \"Other Developmental Disability\",\n",
    "    \"Alcohol Related Disorder\", \"Drug Substance Disorder\", \"Opioid Related Disorder\",\n",
    "    \"Mobility Impairment Disorder\", \"Hearing Impairment\", \"Visual Impairment\", \"Speech Impairment\",\n",
    "    \"Hyperlipidemia\", \"High Blood Pressure\", \"Diabetes\", \"Obesity\", \"Heart Attack\", \"Stroke\",\n",
    "    \"Other Cardiac\", \"Pulmonary Asthma\", \"Alzheimer or Dementia\", \"Kidney Disease\", \"Liver Disease\",\n",
    "    \"Endocrine Condition\", \"Neurological Condition\", \"Traumatic Brain Injury\", \"Joint Disease\", \n",
    "    \"Cancer\", \"Other Chronic Med Condition\", \"No Chronic Med Condition\", \"Unknown Chronic Med Condition\",\n",
    "    \"Cannabis Recreational Use\", \"Cannabis Medicinal Use\", \"Smokes\", \"Received Smoking Medication\",\n",
    "    \"Received Smoking Counseling\", \"Serious Mental Illness\", \"Alcohol 12m Service\", \"Opioid 12m Service\",\n",
    "    \"Drug/Substance 12m Service\", \"Program Category\"\n",
    "]\n",
    "\n",
    "insurance_cols = [\n",
    "    \"SSI Cash Assistance\", \"SSDI Cash Assistance\", \"Veterans Disability Benefits\", \n",
    "    \"Veterans Cash Assistance\", \"Public Assistance Cash Program\", \"Other Cash Benefits\",\n",
    "    \"Medicaid and Medicare Insurance\", \"No Insurance\", \"Unknown Insurance Coverage\", \n",
    "    \"Medicaid Insurance\", \"Medicaid Managed Insurance\", \"Medicare Insurance\", \n",
    "    \"Private Insurance\", \"Child Health Plus Insurance\", \"Other Insurance\"\n",
    "]\n",
    "\n",
    "# Combine all input columns\n",
    "input_columns = demographic_cols + social_cols + clinic_cols + insurance_cols\n",
    "\n",
    "# === 3. Encode categorical variables ===\n",
    "df_encoded = df[input_columns].copy()\n",
    "label_encoders = {}\n",
    "\n",
    "for col in df_encoded.columns:\n",
    "    le = LabelEncoder()\n",
    "    df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# === 4. Correlation analysis (on a sample for performance) ===\n",
    "sample = df_encoded.sample(n=190000, random_state=42)\n",
    "correlation_matrix = sample.corr().abs()\n",
    "\n",
    "# === 5. Identify redundant columns (correlation > 0.9) ===\n",
    "redundant_columns = set()\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if correlation_matrix.iloc[i, j] > 0.9:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            redundant_columns.add(colname)\n",
    "\n",
    "# === 6. Keep only non-redundant representative columns ===\n",
    "non_redundant_columns = [col for col in input_columns if col not in redundant_columns]\n",
    "\n",
    "# === 7. Select top ~20 based on correlation to output (optional logic here) ===\n",
    "# For simplicity, select first 20 non-redundant ones\n",
    "final_input_columns = non_redundant_columns[:20]\n",
    "\n",
    "# Combine with output columns for export\n",
    "final_columns = final_input_columns + output_columns\n",
    "\n",
    "# === 8. Export the reduced dataset ===\n",
    "df_reduced = df[final_columns]\n",
    "df_reduced.to_csv(\"reduced_patient_dataset.csv\", index=False)\n",
    "\n",
    "# === 9. Summary ===\n",
    "print(\"Initial input columns:\", len(input_columns))\n",
    "print(\"Redundant columns removed:\", len(redundant_columns))\n",
    "print(\"Final selected input columns (~20):\")\n",
    "for col in final_input_columns:\n",
    "    print(\" -\", col)\n",
    "print(\"\\nReduced dataset saved to 'reduced_patient_dataset.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a1610db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Reduced dataset exported successfully to:\n",
      "C:/Dell/All Documents/Vợ iu/University/DSTI/Course 1 - Machine Learning with Python Labs/Project 2/reduced_patient_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# === Export reduced dataset to CSV ===\n",
    "df_reduced.to_csv(\"C:/Dell/All Documents/Vợ iu/University/DSTI/Course 1 - Machine Learning with Python Labs/Project 2/reduced_patient_dataset.csv\", index=False)\n",
    "\n",
    "print(\"✅ Reduced dataset exported successfully to:\")\n",
    "print(\"C:/Dell/All Documents/Vợ iu/University/DSTI/Course 1 - Machine Learning with Python Labs/Project 2/reduced_patient_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76a3bb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96     35613\n",
      "           1       0.04      0.01      0.02       307\n",
      "           2       0.12      0.02      0.03       716\n",
      "           3       0.19      0.04      0.06       336\n",
      "           4       0.27      0.08      0.12       708\n",
      "           5       0.67      0.41      0.51      1541\n",
      "\n",
      "    accuracy                           0.91     39221\n",
      "   macro avg       0.37      0.26      0.28     39221\n",
      "weighted avg       0.88      0.91      0.89     39221\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[35066    65    90    47   124   221]\n",
      " [  288     3     1     2     3    10]\n",
      " [  683     0    14     1     1    17]\n",
      " [  286     1     2    13     6    28]\n",
      " [  609     0     4     1    56    38]\n",
      " [  884     2     2     4    17   632]]\n",
      "✅ Model saved as 'mental_illness_predictor_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# === 1. Load reduced dataset ===\n",
    "df = pd.read_csv(\"C:/Dell/All Documents/Vợ iu/University/DSTI/Course 1 - Machine Learning with Python Labs/Project 2/reduced_patient_dataset.csv\")\n",
    "\n",
    "# === 2. Select inputs and output ===\n",
    "output_col = \"Principal Diagnosis Class\"  # You can change this to \"Additional Diagnosis Class\"\n",
    "X = df.drop(columns=[\"Principal Diagnosis Class\", \"Additional Diagnosis Class\"])\n",
    "y = df[output_col]\n",
    "\n",
    "# === 3. Encode target if it's categorical ===\n",
    "if y.dtype == 'object':\n",
    "    le_target = LabelEncoder()\n",
    "    y = le_target.fit_transform(y)\n",
    "    joblib.dump(le_target, \"label_encoder_target.pkl\")  # Save encoder for later decoding\n",
    "\n",
    "# === 4. Encode categorical inputs if needed ===\n",
    "X_encoded = X.copy()\n",
    "label_encoders = {}\n",
    "for col in X_encoded.columns:\n",
    "    if X_encoded[col].dtype == \"object\":\n",
    "        le = LabelEncoder()\n",
    "        X_encoded[col] = le.fit_transform(X_encoded[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Save input encoders\n",
    "joblib.dump(label_encoders, \"input_label_encoders.pkl\")\n",
    "\n",
    "# === 5. Split into training and testing sets ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# === 6. Train a Random Forest classifier ===\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# === 7. Make predictions and evaluate ===\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# === 8. Save the model ===\n",
    "joblib.dump(model, \"mental_illness_predictor_model.pkl\")\n",
    "print(\"✅ Model saved as 'mental_illness_predictor_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c434a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
